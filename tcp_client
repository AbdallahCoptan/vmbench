#!/usr/bin/env python3
#
# Copied with minimal modifications from curio
# https://github.com/dabeaz/curio


import argparse
from concurrent import futures
import socket
import time

import numpy as np


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--msize', default=1000, type=int,
                        help='message size in bytes')
    parser.add_argument('--duration', '-T', default=30, type=int,
                        help='duration of test in seconds')
    parser.add_argument('--times', default=1, type=int,
                        help='number of times to run the test')
    parser.add_argument('--concurrency', default=3, type=int,
                        help='request concurrency')
    parser.add_argument('--timeout', default=2, type=int,
                        help='socket timeout in seconds')
    parser.add_argument('--addr', default='127.0.0.1:25000', type=str,
                        help='server address')
    args = parser.parse_args()

    unix = False
    if args.addr.startswith('file:'):
        unix = True
        addr = args.addr[5:]
    else:
        addr = args.addr.split(':')
        addr[1] = int(addr[1])
        addr = tuple(addr)

    MSGSIZE = args.msize

    msg = b'x' * MSGSIZE

    timeout = args.timeout * 1000

    def run_test(start, duration):
        if unix:
            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        else:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

        sock.settimeout(5)
        sock.connect(addr)

        n = 0
        latency_stats = np.zeros((timeout * 10,))

        while time.monotonic() - start < duration:
            req_start = time.monotonic()
            sock.sendall(msg)
            nrecv = 0
            while nrecv < MSGSIZE:
                resp = sock.recv(MSGSIZE)
                if not resp:
                    raise SystemExit()
                nrecv += len(resp)
            req_time = round((time.monotonic() - req_start) * 10000)
            latency_stats[req_time] += 1
            n += 1

        return n, latency_stats

    def weighted_quantile(values, quantiles, sample_weight=None,
                          values_sorted=False, old_style=False):
        """ Very close to np.percentile, but supports weights.
        NOTE: quantiles should be in [0, 1]!
        :param values: np.array with data
        :param quantiles: array-like with many quantiles needed
        :param sample_weight: array-like of the same length as `array`
        :param values_sorted: bool, if True, then will avoid sorting of initial array
        :param old_style: if True, will correct output to be consistent with np.percentile.
        :return: np.array with computed quantiles.
        """
        values = np.array(values)
        quantiles = np.array(quantiles)
        if sample_weight is None:
            sample_weight = np.ones(len(values))
        sample_weight = np.array(sample_weight)
        assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \
                     'quantiles should be in [0, 1]'

        if not values_sorted:
            sorter = np.argsort(values)
            values = values[sorter]
            sample_weight = sample_weight[sorter]

        weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight
        if old_style:
            # To be convenient with np.percentile
            weighted_quantiles -= weighted_quantiles[0]
            weighted_quantiles /= weighted_quantiles[-1]
        else:
            weighted_quantiles /= np.sum(sample_weight)
        return np.interp(quantiles, weighted_quantiles, values)

    TIMES = args.times
    N = args.concurrency
    DURATION = args.duration

    messages = 0
    latency_stats = None
    start = time.monotonic()
    for _ in range(TIMES):
        with futures.ProcessPoolExecutor(max_workers=N) as e:
            fs = []
            for _ in range(N):
                fs.append(e.submit(run_test, start, DURATION))

            res = futures.wait(fs)
            for fut in res.done:
                t_messages, t_latency_stats = fut.result()
                messages += t_messages
                if latency_stats is None:
                    latency_stats = t_latency_stats
                else:
                    latency_stats = np.add(latency_stats, t_latency_stats)

    end = time.monotonic()
    duration = end - start

    arange = np.arange(len(latency_stats))

    weighted_latency = np.multiply(latency_stats, arange)
    mean_latency = np.sum(weighted_latency) / messages

    percentiles = [50, 75, 90, 99]
    percentile_data = []

    quantiles = weighted_quantile(arange, [p / 100 for p in percentiles],
                                  sample_weight=latency_stats,
                                  values_sorted=True)

    for i, percentile in enumerate(percentiles):
        percentile_data.append('{}%: {}ms'.format(
            percentile, round(quantiles[i], 2)))

    print(messages, 'in', round(duration, 2))
    print('Latency avg: {}ms'.format(round(mean_latency, 2)))
    print('Latency distribution: {}'.format('; '.join(percentile_data)))
    print('Requests/sec: {}'.format(round(messages / duration, 2)))
    transfer = (messages * MSGSIZE / (1024 * 1024)) / duration
    print('Transfer/sec: {}MiB'.format(round(transfer, 2)))
